name: Email Engagement Automation

on:
  schedule:
    # Run daily at 10 AM UTC (morning engagement)
    - cron: '0 10 * * *'
    # Run again at 6 PM UTC (evening engagement)  
    - cron: '0 18 * * *'
  workflow_dispatch:
    inputs:
      engagement_only:
        description: 'Run engagement only (skip confirmations)'
        required: false
        default: false
        type: boolean
      confirmations_only:
        description: 'Run confirmations only (skip engagement)'
        required: false
        default: false
        type: boolean
      max_confirmations:
        description: 'Maximum number of confirmations to process'
        required: false
        type: string
      max_engagements:
        description: 'Maximum number of brands to engage with'
        required: false
        type: string
      dry_run:
        description: 'Dry run - query emails but dont click links'
        required: false
        default: false
        type: boolean

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'

jobs:
  email-engagement:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # 1 hour max (much faster without browser)
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create BigQuery credentials
      run: |
        echo '${{ secrets.BIGQUERY_CREDENTIALS }}' > bigquery_credentials.json
    
    - name: Set engagement parameters
      run: |
        # Set parameters from inputs or defaults
        ENGAGEMENT_ONLY="${{ github.event.inputs.engagement_only || 'false' }}"
        CONFIRMATIONS_ONLY="${{ github.event.inputs.confirmations_only || 'false' }}"
        MAX_CONFIRMATIONS="${{ github.event.inputs.max_confirmations || '20' }}"
        MAX_ENGAGEMENTS="${{ github.event.inputs.max_engagements || '30' }}"
        DRY_RUN="${{ github.event.inputs.dry_run || 'false' }}"
        
        echo "ENGAGEMENT_ONLY=$ENGAGEMENT_ONLY" >> $GITHUB_ENV
        echo "CONFIRMATIONS_ONLY=$CONFIRMATIONS_ONLY" >> $GITHUB_ENV
        echo "MAX_CONFIRMATIONS=$MAX_CONFIRMATIONS" >> $GITHUB_ENV
        echo "MAX_ENGAGEMENTS=$MAX_ENGAGEMENTS" >> $GITHUB_ENV
        echo "DRY_RUN=$DRY_RUN" >> $GITHUB_ENV
        
        echo "ðŸ¤– Email Engagement Bot Parameters:"
        echo "   Engagement only: $ENGAGEMENT_ONLY"
        echo "   Confirmations only: $CONFIRMATIONS_ONLY"
        echo "   Max confirmations: $MAX_CONFIRMATIONS"
        echo "   Max engagements: $MAX_ENGAGEMENTS"
        echo "   Dry run: $DRY_RUN"
    
    - name: Create logs directory
      run: |
        mkdir -p logs
        echo "ðŸ“ Created logs directory"
    
    - name: Download previous engagement state
      continue-on-error: true
      run: |
        # Try to download previous engagement state from artifacts
        echo "ðŸ“¥ Attempting to restore previous engagement state..."
        # This will be implemented to download from previous successful runs
        
    - name: Run email engagement automation
      run: |
        echo "ðŸ¤– Starting email engagement automation..."
        
        # Build command with parameters
        CMD="python email_engagement_bot_simple.py"
        
        # Add parameter flags based on inputs
        if [ "$ENGAGEMENT_ONLY" = "true" ]; then
          CMD="$CMD --engagement-only"
        fi
        
        if [ "$CONFIRMATIONS_ONLY" = "true" ]; then
          CMD="$CMD --confirmations-only"
        fi
        
        if [ "$DRY_RUN" = "true" ]; then
          CMD="$CMD --dry-run"
        fi
        
        echo "ðŸŽ¯ Executing: $CMD"
        eval $CMD
    
    - name: Generate engagement report
      if: always()
      run: |
        echo "ðŸ“Š Generating engagement report..."
        python -c "
        import json
        import os
        from datetime import datetime
        from pathlib import Path
        
        print('ðŸ¤– EMAIL ENGAGEMENT BOT REPORT')
        print('=' * 50)
        print(f'Run Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M UTC\")}')
        print(f'Parameters: Confirmations={os.environ.get(\"CONFIRMATIONS_ONLY\", \"false\")}, Engagements={os.environ.get(\"ENGAGEMENT_ONLY\", \"false\")}, Dry Run={os.environ.get(\"DRY_RUN\", \"false\")}')
        print()
        
        # Check if engagement state exists
        if Path('engagement_tracking.json').exists():
            with open('engagement_tracking.json', 'r') as f:
                state = json.load(f)
            
            confirmations = state.get('confirmations', {})
            engagements = state.get('engagements', {})
            
            print(f'ðŸ“Š CURRENT STATE:')
            print(f'  âœ… Brands with confirmed subscriptions: {len(confirmations)}')
            print(f'  ðŸŽ¯ Brands with engagements: {len(engagements)}')
            print(f'  ðŸ“… Last run: {state.get(\"last_run\", \"Never\")}')
            print()
            
            # Show recent engagements
            if engagements:
                print('ðŸ”¥ RECENT ENGAGEMENTS:')
                sorted_engagements = sorted(
                    engagements.items(), 
                    key=lambda x: x[1].get('last_engaged', ''), 
                    reverse=True
                )
                for brand, data in sorted_engagements[:10]:
                    last_engaged = data.get('last_engaged', 'Never')[:10]
                    count = data.get('engagement_count', 0)
                    print(f'  ðŸŽ¯ {brand}: {count} engagements (last: {last_engaged})')
        else:
            print('âš ï¸ No engagement state file found')
        "
    
    - name: Upload engagement logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: email-engagement-logs-${{ github.run_number }}
        path: |
          engagement_tracking.json
          logs/
        retention-days: 30
    
    - name: Upload engagement state to BigQuery
      if: success()
      run: |
        echo "ðŸ“¤ Uploading engagement state to BigQuery..."
        python -c "
        import json
        import os
        from google.cloud import bigquery
        from google.oauth2 import service_account
        from datetime import datetime
        
        # Setup BigQuery client
        credentials = service_account.Credentials.from_service_account_file('bigquery_credentials.json')
        client = bigquery.Client(credentials=credentials, project='instant-ground-394115')
        
        # Read engagement state
        if os.path.exists('engagement_tracking.json'):
            with open('engagement_tracking.json', 'r') as f:
                state = json.load(f)
            
            # Prepare data for BigQuery
            engagement_records = []
            
            # Process confirmations
            for brand, data in state.get('confirmations', {}).items():
                engagement_records.append({
                    'brand_domain': brand,
                    'engagement_type': 'confirmation',
                    'last_activity': data.get('last_confirmed'),
                    'activity_count': len(data.get('confirmation_urls', [])),
                    'last_url': None,
                    'updated_at': datetime.now().isoformat()
                })
            
            # Process engagements
            for brand, data in state.get('engagements', {}).items():
                engagement_records.append({
                    'brand_domain': brand,
                    'engagement_type': 'engagement',
                    'last_activity': data.get('last_engaged'),
                    'activity_count': data.get('engagement_count', 0),
                    'last_url': data.get('last_url'),
                    'updated_at': datetime.now().isoformat()
                })
            
            if engagement_records:
                # Upload to BigQuery
                table_id = 'instant-ground-394115.email_analytics.engagement_tracking'
                
                try:
                    job_config = bigquery.LoadJobConfig(
                        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,
                        autodetect=True,
                    )
                    
                    job = client.load_table_from_json(
                        engagement_records, 
                        table_id, 
                        job_config=job_config
                    )
                    job.result()
                    
                    print(f'âœ… Uploaded {len(engagement_records)} engagement records to BigQuery')
                except Exception as e:
                    print(f'âš ï¸ Could not upload to BigQuery: {e}')
            else:
                print('â„¹ï¸ No engagement records to upload')
        else:
            print('âš ï¸ No engagement state file found')
        "
    
    - name: Summary
      if: always()
      run: |
        echo "âœ… Email engagement automation complete!"
        echo "ðŸ¤– Bot processed subscription confirmations and brand engagements"
        echo "ðŸ“Š Check artifacts for detailed logs and engagement state"
        echo "ðŸ” Check BigQuery for engagement tracking data"
        echo "ðŸ’¡ Next run scheduled for tomorrow at 10 AM UTC"

  email-analysis:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Write GCP credentials to file
        run: echo '${{ secrets.BIGQUERY_CREDENTIALS }}' > gcp-service-account.json

      - name: Set environment variables for Azure OpenAI
        run: |
          echo "AZURE_OPENAI_API_KEY=${{ secrets.AZURE_OPENAI_API_KEY }}" >> $GITHUB_ENV
          echo "AZURE_OPENAI_ENDPOINT=${{ secrets.AZURE_OPENAI_ENDPOINT }}" >> $GITHUB_ENV
          echo "AZURE_OPENAI_DEPLOYMENT_NAME=${{ secrets.AZURE_OPENAI_DEPLOYMENT_NAME }}" >> $GITHUB_ENV
          echo "GOOGLE_APPLICATION_CREDENTIALS=${{ github.workspace }}/gcp-service-account.json" >> $GITHUB_ENV

      - name: Run production email analysis pipeline
        run: python3 src/production_email_pipeline.py
        env:
          EMAIL_ANALYSIS_LIMIT: 10
          GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/gcp-service-account.json
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          AZURE_OPENAI_DEPLOYMENT_NAME: ${{ secrets.AZURE_OPENAI_DEPLOYMENT_NAME }} 